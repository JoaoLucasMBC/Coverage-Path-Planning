{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "692af511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import random\n",
    "from gymnasium import spaces\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6dbf376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_reachable(grid, start, targets):\n",
    "    \"\"\"\n",
    "    Check if all target cells are reachable from start on grid (0=free, 1=obstacle).\n",
    "    \"\"\"\n",
    "    H, W = grid.shape\n",
    "    visited = np.zeros_like(grid, dtype=bool)\n",
    "    queue = deque([start])\n",
    "    visited[start] = True\n",
    "    reached = set()\n",
    "    while queue:\n",
    "        i, j = queue.popleft()\n",
    "        if (i, j) in targets:\n",
    "            reached.add((i, j))\n",
    "            if reached == set(targets):\n",
    "                return True\n",
    "        for di, dj in ((1,0),(-1,0),(0,1),(0,-1)):\n",
    "            ni, nj = i+di, j+dj\n",
    "            if 0 <= ni < H and 0 <= nj < W and not visited[ni, nj] and grid[ni, nj] == 0:\n",
    "                visited[ni, nj] = True\n",
    "                queue.append((ni, nj))\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d11a8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoverageEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, max_steps=200, seed=None):\n",
    "        super().__init__()\n",
    "        self.H, self.W = 8, 8\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        # seeding for reproducibility\n",
    "        self.seed(seed)\n",
    "\n",
    "        # Action: down, up, right, left\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.Box(0.0, 1.0, shape=(5, self.H, self.W), dtype=np.float32)\n",
    "\n",
    "        # Define a fixed shape library\n",
    "        self.shape_library = [\n",
    "            np.array([[1]]),                # single cell\n",
    "            np.ones((1,3), dtype=int),     # horizontal bar\n",
    "            np.ones((2,2), dtype=int),     # 2x2 block\n",
    "            np.array([[1,1,1],             # U-shape\n",
    "                      [1,0,1],\n",
    "                      [1,1,1]]),\n",
    "            np.array([[1,1,0],             # L-shape\n",
    "                      [1,0,0]])\n",
    "        ]\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        \"\"\"\n",
    "        Seed the environment's RNGs for reproducible layouts.\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"\n",
    "        Reset the environment; returns obs (shape C×H×W), info\n",
    "        Channels:\n",
    "         0 = free space\n",
    "         1 = obstacles\n",
    "         2 = agent location\n",
    "         3 = target area\n",
    "         4 = visited mask (all zeros at reset)\n",
    "        \"\"\"\n",
    "\n",
    "        if seed is not None:\n",
    "            self.seed(42)\n",
    "        else: \n",
    "            self.seed(42)\n",
    "\n",
    "\n",
    "        while True:\n",
    "            grid = np.zeros((self.H, self.W), dtype=int)\n",
    "\n",
    "            num_shapes = np.random.randint(1, len(self.shape_library) + 1)\n",
    "\n",
    "            allowed = random.sample(self.shape_library, num_shapes)\n",
    "\n",
    "            placed = np.zeros_like(grid)\n",
    "            for _ in range(num_shapes):\n",
    "                shape = random.choice(allowed)\n",
    "                sh, sw = shape.shape\n",
    "                i = np.random.randint(0, self.H - sh + 1)\n",
    "                j = np.random.randint(0, self.W - sw + 1)\n",
    "                if not np.any(placed[i:i+sh, j:j+sw] & shape):\n",
    "                    placed[i:i+sh, j:j+sw] |= shape\n",
    "            grid = placed\n",
    "\n",
    "            ti = np.random.randint(0, self.H - 3 + 1)\n",
    "            tj = np.random.randint(0, self.W - 3 + 1)\n",
    "            full_block = [(ti+di, tj+dj) for di in range(3) for dj in range(3)]\n",
    "            targets = [(i,j) for (i,j) in full_block if grid[i,j] == 0]\n",
    "            if not targets:\n",
    "                continue\n",
    "\n",
    "            free_cells = list(zip(*np.where(grid == 0)))\n",
    "            start = random.choice(free_cells)\n",
    "            if bfs_reachable(grid, start, targets):\n",
    "                break\n",
    "\n",
    "        self.grid = grid\n",
    "        self.targets = set(targets)\n",
    "        self.agent_pos = start\n",
    "        self.visited = { start }\n",
    "        self.steps = 0\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        C = 5\n",
    "        state = np.zeros((C, self.H, self.W), dtype=np.float32)\n",
    "\n",
    "        # channel 0: free space (grid==0)\n",
    "        state[0, :, :] = (self.grid == 0).astype(np.float32)\n",
    "        # channel 1: obstacles (grid!=0)\n",
    "        state[1, :, :] = (self.grid != 0).astype(np.float32)\n",
    "        # channel 2: agent location\n",
    "        i, j = self.agent_pos\n",
    "        state[2, i, j] = 1.0\n",
    "        # channel 3: target area\n",
    "        for (ti, tj) in self.targets:\n",
    "            state[3, ti, tj] = 1.0\n",
    "        for vi, vj in self.visited:\n",
    "            state[4, vi, vj] = 1.0\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Define movement vectors\n",
    "        # 0 = down, 1 = up, 2 = right, 3 = left\n",
    "        moves = {0: (1, 0), 1: (-1, 0), 2: (0, 1), 3: (0, -1)}\n",
    "        i, j = self.agent_pos\n",
    "        di, dj = moves[action]\n",
    "        ni, nj = i + di, j + dj\n",
    "\n",
    "        # Default baseline reward\n",
    "        reward = 0\n",
    "\n",
    "        # Check validity and apply penalties\n",
    "        if not (0 <= ni < self.H and 0 <= nj < self.W and self.grid[ni, nj] == 0):\n",
    "            # Invalid action: stay in place\n",
    "            self.agent_pos = (i, j) \n",
    "        else:\n",
    "            # Valid move: update position\n",
    "            self.agent_pos = (ni, nj)\n",
    "\n",
    "        # Check if on a target\n",
    "        if self.agent_pos not in self.visited:\n",
    "            if self.agent_pos in self.targets:\n",
    "                reward = 2.0   # new target\n",
    "            self.visited.add(self.agent_pos)\n",
    "        else:\n",
    "            reward = -1\n",
    "\n",
    "        # Step count\n",
    "        self.steps += 1\n",
    "\n",
    "        # Terminal bonus\n",
    "        terminated = True\n",
    "        for (i,j) in self.targets:\n",
    "            if (i,j) not in self.visited:\n",
    "                terminated = False\n",
    "                break\n",
    "            \n",
    "        truncated = (self.steps >= self.max_steps)\n",
    "        if terminated:\n",
    "            reward += 30.0\n",
    "\n",
    "        return self._get_obs(), reward, terminated, truncated, {}\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        disp = np.full((self.H, self.W), '.', dtype=str)\n",
    "        for (i,j) in self.targets:\n",
    "            disp[i,j] = 'T'\n",
    "        for (i,j) in zip(*np.where(self.grid == 1)):\n",
    "            disp[i,j] = '#'\n",
    "        ai, aj = self.agent_pos\n",
    "        disp[ai, aj] = 'A'\n",
    "        print(\"\\n\".join(\"\".join(row) for row in disp))\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf072055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedropertusi/Desktop/reinforcement-learning/Coverage-Path-Planning/env/lib/python3.12/site-packages/gymnasium/envs/registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment Coverage-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "gym.register(\n",
    "    id=\"Coverage-v0\",\n",
    "    entry_point=\"coverage_env:CoverageEnv\",\n",
    "    max_episode_steps=200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49d9b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 179      |\n",
      "|    ep_rew_mean     | -139     |\n",
      "| time/              |          |\n",
      "|    fps             | 6506     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 185         |\n",
      "|    ep_rew_mean          | -145        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3809        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008340899 |\n",
      "|    clip_fraction        | 0.00483     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.00149    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 47.1        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    value_loss           | 97.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 177          |\n",
      "|    ep_rew_mean          | -132         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3357         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072114915 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.00488      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 179         |\n",
      "|    ep_rew_mean          | -130        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3179        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011573607 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.000172   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 67.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 177          |\n",
      "|    ep_rew_mean          | -125         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3081         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060249595 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.000198    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 46           |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 169          |\n",
      "|    ep_rew_mean          | -116         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3001         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040107667 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.000105    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 165         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2965        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012227585 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -1.59e-05   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 64.5        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 164         |\n",
      "|    ep_rew_mean          | -110        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2933        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010157882 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 1.91e-06    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 159         |\n",
      "|    ep_rew_mean          | -102        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2904        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007856373 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 6.62e-05    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 89.4        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 156          |\n",
      "|    ep_rew_mean          | -98.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2890         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023382762 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 5.29e-05     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 149          |\n",
      "|    ep_rew_mean          | -89.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2867         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018255698 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.000126     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | -82.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2854        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007080088 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.00017     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 73.9        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 139          |\n",
      "|    ep_rew_mean          | -78.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2847         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015323261 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 66.6         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 140          |\n",
      "|    ep_rew_mean          | -79.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2840         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007090694 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 36.7         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000948    |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 134          |\n",
      "|    ep_rew_mean          | -71.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2834         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045253383 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 47.7         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 84.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 129          |\n",
      "|    ep_rew_mean          | -64.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2830         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026780008 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | -62         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2824        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012419259 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | -61.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2817        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007580557 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 66.4        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 120          |\n",
      "|    ep_rew_mean          | -54.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2809         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096672615 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 44.6         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 119          |\n",
      "|    ep_rew_mean          | -52.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2786         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102167595 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 56.3         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 119          |\n",
      "|    ep_rew_mean          | -52.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2775         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067450143 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 39.3         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 115         |\n",
      "|    ep_rew_mean          | -48.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2761        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009246406 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 56.5        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 113          |\n",
      "|    ep_rew_mean          | -47.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2754         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040411404 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 103          |\n",
      "|    ep_rew_mean          | -38.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2743         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028464226 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 42.8         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94.2         |\n",
      "|    ep_rew_mean          | -30.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2744         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042411108 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 45.4         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91.1         |\n",
      "|    ep_rew_mean          | -26.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2748         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061983177 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 81.5         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00765     |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 87.1         |\n",
      "|    ep_rew_mean          | -22.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2746         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035743592 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 55.6         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 83.7        |\n",
      "|    ep_rew_mean          | -18.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2745        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007547245 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 81.6        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 81.2         |\n",
      "|    ep_rew_mean          | -15.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2747         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059361192 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 58.9         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00824     |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77           |\n",
      "|    ep_rew_mean          | -12.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2743         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053563854 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 68.7         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00779     |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 71.8       |\n",
      "|    ep_rew_mean          | -7.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2744       |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00574469 |\n",
      "|    clip_fraction        | 0.0259     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 38.2       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.00363   |\n",
      "|    value_loss           | 135        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.9         |\n",
      "|    ep_rew_mean          | -5.87        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2745         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065798443 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 95.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 57.3        |\n",
      "|    ep_rew_mean          | 7.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2744        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010037424 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 47.3        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.4         |\n",
      "|    ep_rew_mean          | 12.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2739         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070509147 |\n",
      "|    clip_fraction        | 0.0574       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 37.5         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00867     |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.8        |\n",
      "|    ep_rew_mean          | 18.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2737        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007586006 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 46          |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.7        |\n",
      "|    ep_rew_mean          | 16.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2738        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006441901 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    value_loss           | 84.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.2        |\n",
      "|    ep_rew_mean          | 15          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2742        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006004016 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    value_loss           | 90.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41          |\n",
      "|    ep_rew_mean          | 19.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2745        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007446652 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 90.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.4        |\n",
      "|    ep_rew_mean          | 25.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2746        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008384667 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 89.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.3        |\n",
      "|    ep_rew_mean          | 30.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2748        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006560993 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    value_loss           | 73.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.8        |\n",
      "|    ep_rew_mean          | 32.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2751        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013456529 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.935      |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.4        |\n",
      "|    ep_rew_mean          | 34.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2752        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013884917 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.874      |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.4        |\n",
      "|    ep_rew_mean          | 36.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2751        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008744384 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.4         |\n",
      "|    ep_rew_mean          | 38           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2752         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075694583 |\n",
      "|    clip_fraction        | 0.0757       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.743       |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00956     |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.2        |\n",
      "|    ep_rew_mean          | 38.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2754        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010447137 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 13.8       |\n",
      "|    ep_rew_mean          | 40.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2753       |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00956813 |\n",
      "|    clip_fraction        | 0.0862     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.544     |\n",
      "|    explained_variance   | 0.531      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 7.09       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    value_loss           | 18.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.5        |\n",
      "|    ep_rew_mean          | 41          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2754        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010207788 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.384      |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.63        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 6.84        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 12.9       |\n",
      "|    ep_rew_mean          | 41.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2754       |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01605065 |\n",
      "|    clip_fraction        | 0.0749     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.292     |\n",
      "|    explained_variance   | 0.601      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.29       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00868   |\n",
      "|    value_loss           | 3.51       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 12.6         |\n",
      "|    ep_rew_mean          | 41.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2754         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058215316 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.188       |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.841        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00991     |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# instantiate a single env (you can wrap VecEnv for parallelism later)\n",
    "env = CoverageEnv(seed=42)\n",
    "\n",
    "# create the DQN model\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",      # flatten your 5×8×8 obs into a 320‐dim vector\n",
    "    env=env,             # or env directly if you prefer a single env\n",
    "    learning_rate=1e-4,      # slightly lower than default 3e-4 for stability\n",
    "    n_steps=2048,            # rollout length per update (≈10 episodes worth)\n",
    "    batch_size=64,           # minibatch size for each epoch\n",
    "    n_epochs=10,             # number of passes over the rollout buffer\n",
    "    gamma=0.99,              # reward discount\n",
    "    gae_lambda=0.95,         # GAE smoothing\n",
    "    clip_range=0.2,          # PPO clipping parameter\n",
    "    ent_coef=0.01,           # small entropy bonus to encourage exploration\n",
    "    vf_coef=0.5,             # value function loss coefficient\n",
    "    max_grad_norm=0.5,       # clip gradients\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# train for 50k timesteps\n",
    "model.learn(total_timesteps=100_000)\n",
    "\n",
    "# save it\n",
    "model.save(\"ppo_coverage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10b98190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 42.00 ± 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedropertusi/Desktop/reinforcement-learning/Coverage-Path-Planning/env/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(\n",
    "    model,\n",
    "    env,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "print(f\"Mean reward: {mean_reward:.2f} ± {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "146c345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 action: 2\n",
      "........\n",
      "........\n",
      "..TTT.#.\n",
      "..TTT...\n",
      "..####..\n",
      "..#.#...\n",
      ".##..A..\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 1 action: 2\n",
      "........\n",
      "........\n",
      "..TTT.#.\n",
      "..TTT...\n",
      "..####..\n",
      "..#.#...\n",
      ".##...A.\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 2 action: 1\n",
      "........\n",
      "........\n",
      "..TTT.#.\n",
      "..TTT...\n",
      "..####..\n",
      "..#.#.A.\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 3 action: 1\n",
      "........\n",
      "........\n",
      "..TTT.#.\n",
      "..TTT...\n",
      "..####A.\n",
      "..#.#...\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 4 action: 1\n",
      "........\n",
      "........\n",
      "..TTT.#.\n",
      "..TTT.A.\n",
      "..####..\n",
      "..#.#...\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 5 action: 3\n",
      "........\n",
      "........\n",
      "..TTT.#.\n",
      "..TTTA..\n",
      "..####..\n",
      "..#.#...\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 6 action: 3\n",
      "........\n",
      "........\n",
      "..TTT.#.\n",
      "..TTA...\n",
      "..####..\n",
      "..#.#...\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 7 action: 3\n",
      "........\n",
      "........\n",
      "..TTT.#.\n",
      "..TAT...\n",
      "..####..\n",
      "..#.#...\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 8 action: 3\n",
      "........\n",
      "........\n",
      "..TTT.#.\n",
      "..ATT...\n",
      "..####..\n",
      "..#.#...\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 9 action: 1\n",
      "........\n",
      "........\n",
      "..ATT.#.\n",
      "..TTT...\n",
      "..####..\n",
      "..#.#...\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 10 action: 2\n",
      "........\n",
      "........\n",
      "..TAT.#.\n",
      "..TTT...\n",
      "..####..\n",
      "..#.#...\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "step: 11 action: 2\n",
      "........\n",
      "........\n",
      "..TTA.#.\n",
      "..TTT...\n",
      "..####..\n",
      "..#.#...\n",
      ".##.....\n",
      ".#......\n",
      "\n",
      "\n",
      "\n",
      "Done! Terminated\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset(seed=42)\n",
    "for i in range(env.max_steps):\n",
    "    action_arr, _ = model.predict(obs, deterministic=True)\n",
    "    action = int(action_arr)       # unwrap numpy array\n",
    "    print(\"step:\", i, \"action:\", action)\n",
    "\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    print()  # blank line between frames\n",
    "\n",
    "    if terminated or truncated:\n",
    "        print(\"Done!\", \"Terminated\" if terminated else \"Truncated\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
