{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbaf02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from heapq import heappush, heappop\n",
    "import numpy as np\n",
    "import random\n",
    "from gymnasium import spaces\n",
    "from collections import deque\n",
    "from coverage_env import CoverageEnv\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f204daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(grid, start, goal):\n",
    "    H, W = grid.shape\n",
    "    open_set = [(abs(start[0]-goal[0]) + abs(start[1]-goal[1]), 0, start, None)]\n",
    "    came_from = {}\n",
    "    g_score = {start: 0}\n",
    "    while open_set:\n",
    "        f, g, current, parent = heappop(open_set)\n",
    "        if current == goal:\n",
    "            # reconstrói caminho\n",
    "            path = [current]\n",
    "            while parent:\n",
    "                path.append(parent)\n",
    "                parent = came_from[parent]\n",
    "            return list(reversed(path))\n",
    "        if current in came_from:\n",
    "            continue\n",
    "        came_from[current] = parent\n",
    "        ci, cj = current\n",
    "        for di, dj in [(1,0),(-1,0),(0,1),(0,-1)]:\n",
    "            ni, nj = ci+di, cj+dj\n",
    "            if 0 <= ni < H and 0 <= nj < W and grid[ni,nj]==0:\n",
    "                neigh = (ni,nj)\n",
    "                tentative_g = g + 1\n",
    "                if tentative_g < g_score.get(neigh, 1e9):\n",
    "                    g_score[neigh] = tentative_g\n",
    "                    h = abs(ni-goal[0]) + abs(nj-goal[1])\n",
    "                    heappush(open_set, (tentative_g + h, tentative_g, neigh, current))\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5727c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_with_astar(env):\n",
    "    obs, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    visited = set(env.visited)\n",
    "    done = False\n",
    "    truncated = False\n",
    "\n",
    "    while True:\n",
    "        remaining = list(env.targets - visited)\n",
    "        if not remaining:\n",
    "            break\n",
    "        remaining.sort(key=lambda cell: abs(env.agent_pos[0]-cell[0]) + abs(env.agent_pos[1]-cell[1]))\n",
    "        goal = remaining[0]\n",
    "\n",
    "        path = astar(env.grid, env.agent_pos, goal)\n",
    "        if path is None:\n",
    "            print(f\"Alvo {goal} inacessível\")\n",
    "            break\n",
    "\n",
    "        for next_cell in path[1:]:\n",
    "            ci, cj = env.agent_pos\n",
    "            ni, nj = next_cell\n",
    "            if ni > ci:   action = 0\n",
    "            elif ni < ci: action = 1\n",
    "            elif nj > cj: action = 2\n",
    "            else:         action = 3\n",
    "\n",
    "            obs, reward, done, truncated, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            visited = set(env.visited)\n",
    "            if done or truncated:\n",
    "                break\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "    return total_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b5a8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean A* rewards per curriculum level:\n",
      "  Level 0: 42.25\n",
      "  Level 1: 45.50\n",
      "  Level 2: 40.45\n",
      "  Level 3: 40.65\n",
      "  Level 4: 30.90\n",
      "\n",
      "Max A* rewards per curriculum level:\n",
      "  Level 0: 45.00\n",
      "  Level 1: 48.00\n",
      "  Level 2: 44.00\n",
      "  Level 3: 44.00\n",
      "  Level 4: 36.00\n",
      "\n",
      "Min A* rewards per curriculum level:\n",
      "  Level 0: 40.00\n",
      "  Level 1: 43.00\n",
      "  Level 2: 37.00\n",
      "  Level 3: 38.00\n",
      "  Level 4: 24.00\n"
     ]
    }
   ],
   "source": [
    "num_runs = 20\n",
    "levels = range(5)   \n",
    "mean_rewards = {}\n",
    "max_rewards = {}\n",
    "min_rewards = {}\n",
    "\n",
    "for level in levels:\n",
    "    rewards = []\n",
    "    for run in range(num_runs):\n",
    "        env = CoverageEnv(curriculum=level)   \n",
    "        reward = coverage_with_astar(env)\n",
    "        rewards.append(reward)\n",
    "    mean_rewards[level] = np.mean(rewards)\n",
    "    max_rewards[level] = np.max(rewards)\n",
    "    min_rewards[level] = np.min(rewards)\n",
    "\n",
    "print(\"\\nMean A* rewards per curriculum level:\")\n",
    "for level, mean_r in mean_rewards.items():\n",
    "    print(f\"  Level {level}: {mean_r:.2f}\")\n",
    "\n",
    "print(\"\\nMax A* rewards per curriculum level:\")\n",
    "for level, max_r in max_rewards.items():\n",
    "    print(f\"  Level {level}: {max_r:.2f}\")\n",
    "\n",
    "print(\"\\nMin A* rewards per curriculum level:\")\n",
    "for level, min_r in min_rewards.items():\n",
    "    print(f\"  Level {level}: {min_r:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
