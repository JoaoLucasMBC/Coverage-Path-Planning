{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "654bcffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coverage_env import CoverageEnv\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9df1bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_0 = CoverageEnv(curriculum=0)\n",
    "env_1 = CoverageEnv(curriculum=1)\n",
    "env_2 = CoverageEnv(curriculum=2)\n",
    "env_3 = CoverageEnv(curriculum=3)\n",
    "env_4 = CoverageEnv(curriculum=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a41ed3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at most 16 arguments, got 18\n",
      "  warnings.warn(\n",
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object exploration_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at most 16 arguments, got 18\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_dqn_0 = DQN.load(\"models/dqn/mlp/coverage_lvl0.zip\")\n",
    "model_dqn_1 = DQN.load(\"models/dqn/mlp/coverage_lvl1.zip\")\n",
    "model_dqn_2 = DQN.load(\"models/dqn/mlp/coverage_lvl2.zip\")\n",
    "model_dqn_3 = DQN.load(\"models/dqn/mlp/coverage_lvl3.zip\")\n",
    "model_dqn_4 = DQN.load(\"models/dqn/mlp/coverage_lvl4.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e42bd1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mean_reward_dqn_0, std_reward_dqn_0 = evaluate_policy(\n",
    "    model_dqn_0, \n",
    "    env_0,\n",
    "    n_eval_episodes=20, \n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "mean_reward_dqn_1, std_reward_dqn_1 = evaluate_policy(\n",
    "    model_dqn_1, \n",
    "    env_1,\n",
    "    n_eval_episodes=20, \n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "mean_reward_dqn_2, std_reward_dqn_2 = evaluate_policy(\n",
    "    model_dqn_2, \n",
    "    env_2,\n",
    "    n_eval_episodes=20, \n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "mean_reward_dqn_3, std_reward_dqn_3 = evaluate_policy(\n",
    "    model_dqn_3, \n",
    "    env_3,\n",
    "    n_eval_episodes=20, \n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "mean_reward_dqn_4, std_reward_dqn_4 = evaluate_policy(\n",
    "    model_dqn_4, \n",
    "    env_4,\n",
    "    n_eval_episodes=20, \n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "# Put all results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Curriculum\": [\"Level 0\", \"Level 1\", \"Level 2\", \"Level 3\", \"Level 4\"],\n",
    "    \"Model\": [\n",
    "        \"DQN\",\n",
    "        \"DQN\",\n",
    "        \"DQN\",\n",
    "        \"DQN\",\n",
    "        \"DQN\",\n",
    "    ],\n",
    "    \"Mean Reward\": [\n",
    "        mean_reward_dqn_0,\n",
    "        mean_reward_dqn_1,\n",
    "        mean_reward_dqn_2,\n",
    "        mean_reward_dqn_3,\n",
    "        mean_reward_dqn_4,\n",
    "    ],\n",
    "    \"Std Reward\": [\n",
    "        std_reward_dqn_0,\n",
    "        std_reward_dqn_1,\n",
    "        std_reward_dqn_2,\n",
    "        std_reward_dqn_3,\n",
    "        std_reward_dqn_4,\n",
    "    ],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bf75e3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curriculum</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Reward</th>\n",
       "      <th>Std Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>DQN</td>\n",
       "      <td>41.95</td>\n",
       "      <td>1.283550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>DQN</td>\n",
       "      <td>45.40</td>\n",
       "      <td>1.743560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>DQN</td>\n",
       "      <td>37.45</td>\n",
       "      <td>3.201172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>DQN</td>\n",
       "      <td>28.30</td>\n",
       "      <td>48.992959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>DQN</td>\n",
       "      <td>-198.50</td>\n",
       "      <td>3.074085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Curriculum Model  Mean Reward  Std Reward\n",
       "0    Level 0   DQN        41.95    1.283550\n",
       "1    Level 1   DQN        45.40    1.743560\n",
       "2    Level 2   DQN        37.45    3.201172\n",
       "3    Level 3   DQN        28.30   48.992959\n",
       "4    Level 4   DQN      -198.50    3.074085"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "be613798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at most 16 arguments, got 18\n",
      "  warnings.warn(\n",
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at most 16 arguments, got 18\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Do the same for ppo/no_l2/ folder\n",
    "model_ppo_0 = PPO.load(\"models/ppo/no_l2/mlp_coverage_lvl0.zip\")\n",
    "model_ppo_1 = PPO.load(\"models/ppo/no_l2/mlp_coverage_lvl1.zip\")\n",
    "model_ppo_2 = PPO.load(\"models/ppo/no_l2/mlp_coverage_lvl2.zip\")\n",
    "model_ppo_3 = PPO.load(\"models/ppo/no_l2/mlp_coverage_lvl3.zip\")\n",
    "model_ppo_4 = PPO.load(\"models/ppo/no_l2/mlp_coverage_lv4.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8dbe94ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mean_reward_ppo_0, std_reward_ppo_0 = evaluate_policy(\n",
    "    model_ppo_0,\n",
    "    env_0,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "mean_reward_ppo_1, std_reward_ppo_1 = evaluate_policy(\n",
    "    model_ppo_1,\n",
    "    env_1,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "mean_reward_ppo_2, std_reward_ppo_2 = evaluate_policy(\n",
    "    model_ppo_2,\n",
    "    env_2,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")  \n",
    "mean_reward_ppo_3, std_reward_ppo_3 = evaluate_policy(\n",
    "    model_ppo_3,\n",
    "    env_3,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "mean_reward_ppo_4, std_reward_ppo_4 = evaluate_policy(\n",
    "    model_ppo_4,\n",
    "    env_4,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "# Create the new rows as DataFrames\n",
    "ppo_results = pd.DataFrame([\n",
    "    {\"Curriculum\": \"Level 0\", \"Model\": \"PPO\", \"Mean Reward\": mean_reward_ppo_0, \"Std Reward\": std_reward_ppo_0},\n",
    "    {\"Curriculum\": \"Level 1\", \"Model\": \"PPO\", \"Mean Reward\": mean_reward_ppo_1, \"Std Reward\": std_reward_ppo_1},\n",
    "    {\"Curriculum\": \"Level 2\", \"Model\": \"PPO\", \"Mean Reward\": mean_reward_ppo_2, \"Std Reward\": std_reward_ppo_2},\n",
    "    {\"Curriculum\": \"Level 3\", \"Model\": \"PPO\", \"Mean Reward\": mean_reward_ppo_3, \"Std Reward\": std_reward_ppo_3},\n",
    "    {\"Curriculum\": \"Level 4\", \"Model\": \"PPO\", \"Mean Reward\": mean_reward_ppo_4, \"Std Reward\": std_reward_ppo_4}\n",
    "])\n",
    "\n",
    "# Concatenate the new rows to the existing DataFrame\n",
    "results = pd.concat([results, ppo_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "78d293de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curriculum</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Reward</th>\n",
       "      <th>Std Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>DQN</td>\n",
       "      <td>41.95</td>\n",
       "      <td>1.283550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>DQN</td>\n",
       "      <td>45.40</td>\n",
       "      <td>1.743560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>DQN</td>\n",
       "      <td>37.45</td>\n",
       "      <td>3.201172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>DQN</td>\n",
       "      <td>28.30</td>\n",
       "      <td>48.992959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>DQN</td>\n",
       "      <td>-198.50</td>\n",
       "      <td>3.074085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>PPO</td>\n",
       "      <td>43.35</td>\n",
       "      <td>1.152172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>PPO</td>\n",
       "      <td>20.55</td>\n",
       "      <td>73.533309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>PPO</td>\n",
       "      <td>39.50</td>\n",
       "      <td>2.418677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>PPO</td>\n",
       "      <td>41.15</td>\n",
       "      <td>2.219797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>PPO</td>\n",
       "      <td>30.70</td>\n",
       "      <td>2.325941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Curriculum Model  Mean Reward  Std Reward\n",
       "0    Level 0   DQN        41.95    1.283550\n",
       "1    Level 1   DQN        45.40    1.743560\n",
       "2    Level 2   DQN        37.45    3.201172\n",
       "3    Level 3   DQN        28.30   48.992959\n",
       "4    Level 4   DQN      -198.50    3.074085\n",
       "5    Level 0   PPO        43.35    1.152172\n",
       "6    Level 1   PPO        20.55   73.533309\n",
       "7    Level 2   PPO        39.50    2.418677\n",
       "8    Level 3   PPO        41.15    2.219797\n",
       "9    Level 4   PPO        30.70    2.325941"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b577cc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at most 16 arguments, got 18\n",
      "  warnings.warn(\n",
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at most 16 arguments, got 18\n",
      "  warnings.warn(\n",
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Lastly, do the same for ppo/l2/ folder\n",
    "model_ppo_l2_0 = PPO.load(\"models/ppo/l2/mlp_coverage_lvl0.zip\")\n",
    "model_ppo_l2_1 = PPO.load(\"models/ppo/l2/mlp_coverage_lvl1.zip\")\n",
    "model_ppo_l2_2 = PPO.load(\"models/ppo/l2/mlp_coverage_lvl2.zip\")\n",
    "model_ppo_l2_3 = PPO.load(\"models/ppo/l2/mlp_coverage_lvl3.zip\")\n",
    "model_ppo_l2_4 = PPO.load(\"models/ppo/l2/mlp_coverage_lvl4.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d5e15b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaolucasmbc/mambaforge/envs/rl-cpp/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mean_reward_ppo_l2_0, std_reward_ppo_l2_0 = evaluate_policy(\n",
    "    model_ppo_l2_0,\n",
    "    env_0,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "mean_reward_ppo_l2_1, std_reward_ppo_l2_1 = evaluate_policy(\n",
    "    model_ppo_l2_1,\n",
    "    env_1,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "mean_reward_ppo_l2_2, std_reward_ppo_l2_2 = evaluate_policy(\n",
    "    model_ppo_l2_2,\n",
    "    env_2,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "mean_reward_ppo_l2_3, std_reward_ppo_l2_3 = evaluate_policy(\n",
    "    model_ppo_l2_3,\n",
    "    env_3,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")\n",
    "mean_reward_ppo_l2_4, std_reward_ppo_l2_4 = evaluate_policy(\n",
    "    model_ppo_l2_4,\n",
    "    env_4,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    ")  \n",
    "\n",
    "# Create the new rows as DataFrames\n",
    "ppo_l2_results = pd.DataFrame([\n",
    "    {\"Curriculum\": \"Level 0\", \"Model\": \"PPO L2\", \"Mean Reward\": mean_reward_ppo_l2_0, \"Std Reward\": std_reward_ppo_l2_0},\n",
    "    {\"Curriculum\": \"Level 1\", \"Model\": \"PPO L2\", \"Mean Reward\": mean_reward_ppo_l2_1, \"Std Reward\": std_reward_ppo_l2_1},\n",
    "    {\"Curriculum\": \"Level 2\", \"Model\": \"PPO L2\", \"Mean Reward\": mean_reward_ppo_l2_2, \"Std Reward\": std_reward_ppo_l2_2},\n",
    "    {\"Curriculum\": \"Level 3\", \"Model\": \"PPO L2\", \"Mean Reward\": mean_reward_ppo_l2_3, \"Std Reward\": std_reward_ppo_l2_3},\n",
    "    {\"Curriculum\": \"Level 4\", \"Model\": \"PPO L2\", \"Mean Reward\": mean_reward_ppo_l2_4, \"Std Reward\": std_reward_ppo_l2_4}\n",
    "])\n",
    "# Concatenate the new rows to the existing DataFrame\n",
    "results = pd.concat([results, ppo_l2_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fef099bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curriculum</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Reward</th>\n",
       "      <th>Std Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>DQN</td>\n",
       "      <td>41.95</td>\n",
       "      <td>1.283550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>DQN</td>\n",
       "      <td>45.40</td>\n",
       "      <td>1.743560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>DQN</td>\n",
       "      <td>37.45</td>\n",
       "      <td>3.201172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>DQN</td>\n",
       "      <td>28.30</td>\n",
       "      <td>48.992959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>DQN</td>\n",
       "      <td>-198.50</td>\n",
       "      <td>3.074085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>PPO</td>\n",
       "      <td>43.35</td>\n",
       "      <td>1.152172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>PPO</td>\n",
       "      <td>20.55</td>\n",
       "      <td>73.533309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>PPO</td>\n",
       "      <td>39.50</td>\n",
       "      <td>2.418677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>PPO</td>\n",
       "      <td>41.15</td>\n",
       "      <td>2.219797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>PPO</td>\n",
       "      <td>30.70</td>\n",
       "      <td>2.325941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>42.95</td>\n",
       "      <td>1.745709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>44.20</td>\n",
       "      <td>1.964688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>39.35</td>\n",
       "      <td>2.104163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>14.85</td>\n",
       "      <td>71.654920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>20.55</td>\n",
       "      <td>47.915003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Curriculum   Model  Mean Reward  Std Reward\n",
       "0     Level 0     DQN        41.95    1.283550\n",
       "1     Level 1     DQN        45.40    1.743560\n",
       "2     Level 2     DQN        37.45    3.201172\n",
       "3     Level 3     DQN        28.30   48.992959\n",
       "4     Level 4     DQN      -198.50    3.074085\n",
       "5     Level 0     PPO        43.35    1.152172\n",
       "6     Level 1     PPO        20.55   73.533309\n",
       "7     Level 2     PPO        39.50    2.418677\n",
       "8     Level 3     PPO        41.15    2.219797\n",
       "9     Level 4     PPO        30.70    2.325941\n",
       "10    Level 0  PPO L2        42.95    1.745709\n",
       "11    Level 1  PPO L2        44.20    1.964688\n",
       "12    Level 2  PPO L2        39.35    2.104163\n",
       "13    Level 3  PPO L2        14.85   71.654920\n",
       "14    Level 4  PPO L2        20.55   47.915003"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b51d0f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75681/244630703.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, astar_results], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#Mean A* rewards per curriculum level:\n",
    "#  Level 0: 42.25\n",
    "#  Level 1: 45.50\n",
    "#  Level 2: 40.45\n",
    "#  Level 3: 40.65\n",
    "#  Level 4: 30.90\n",
    "\n",
    "# Add the A* results to the DataFrame without standard deviation\n",
    "astar_results = pd.DataFrame([\n",
    "    {\"Curriculum\": \"Level 0\", \"Model\": \"A*\", \"Mean Reward\": 42.25, \"Std Reward\": None},\n",
    "    {\"Curriculum\": \"Level 1\", \"Model\": \"A*\", \"Mean Reward\": 45.50, \"Std Reward\": None},\n",
    "    {\"Curriculum\": \"Level 2\", \"Model\": \"A*\", \"Mean Reward\": 40.45, \"Std Reward\": None},\n",
    "    {\"Curriculum\": \"Level 3\", \"Model\": \"A*\", \"Mean Reward\": 40.65, \"Std Reward\": None},\n",
    "    {\"Curriculum\": \"Level 4\", \"Model\": \"A*\", \"Mean Reward\": 30.90, \"Std Reward\": None}\n",
    "])\n",
    "# Concatenate the A* results to the existing DataFrame\n",
    "results = pd.concat([results, astar_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "98089c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curriculum</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Reward</th>\n",
       "      <th>Std Reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>DQN</td>\n",
       "      <td>41.95</td>\n",
       "      <td>1.283550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>DQN</td>\n",
       "      <td>45.40</td>\n",
       "      <td>1.743560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>DQN</td>\n",
       "      <td>37.45</td>\n",
       "      <td>3.201172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>DQN</td>\n",
       "      <td>28.30</td>\n",
       "      <td>48.992959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>DQN</td>\n",
       "      <td>-198.50</td>\n",
       "      <td>3.074085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>PPO</td>\n",
       "      <td>43.35</td>\n",
       "      <td>1.152172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>PPO</td>\n",
       "      <td>20.55</td>\n",
       "      <td>73.533309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>PPO</td>\n",
       "      <td>39.50</td>\n",
       "      <td>2.418677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>PPO</td>\n",
       "      <td>41.15</td>\n",
       "      <td>2.219797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>PPO</td>\n",
       "      <td>30.70</td>\n",
       "      <td>2.325941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>42.95</td>\n",
       "      <td>1.745709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>44.20</td>\n",
       "      <td>1.964688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>39.35</td>\n",
       "      <td>2.104163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>14.85</td>\n",
       "      <td>71.654920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>PPO L2</td>\n",
       "      <td>20.55</td>\n",
       "      <td>47.915003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Level 0</td>\n",
       "      <td>A*</td>\n",
       "      <td>42.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Level 1</td>\n",
       "      <td>A*</td>\n",
       "      <td>45.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Level 2</td>\n",
       "      <td>A*</td>\n",
       "      <td>40.45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Level 3</td>\n",
       "      <td>A*</td>\n",
       "      <td>40.65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Level 4</td>\n",
       "      <td>A*</td>\n",
       "      <td>30.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Curriculum   Model  Mean Reward  Std Reward\n",
       "0     Level 0     DQN        41.95    1.283550\n",
       "1     Level 1     DQN        45.40    1.743560\n",
       "2     Level 2     DQN        37.45    3.201172\n",
       "3     Level 3     DQN        28.30   48.992959\n",
       "4     Level 4     DQN      -198.50    3.074085\n",
       "5     Level 0     PPO        43.35    1.152172\n",
       "6     Level 1     PPO        20.55   73.533309\n",
       "7     Level 2     PPO        39.50    2.418677\n",
       "8     Level 3     PPO        41.15    2.219797\n",
       "9     Level 4     PPO        30.70    2.325941\n",
       "10    Level 0  PPO L2        42.95    1.745709\n",
       "11    Level 1  PPO L2        44.20    1.964688\n",
       "12    Level 2  PPO L2        39.35    2.104163\n",
       "13    Level 3  PPO L2        14.85   71.654920\n",
       "14    Level 4  PPO L2        20.55   47.915003\n",
       "15    Level 0      A*        42.25         NaN\n",
       "16    Level 1      A*        45.50         NaN\n",
       "17    Level 2      A*        40.45         NaN\n",
       "18    Level 3      A*        40.65         NaN\n",
       "19    Level 4      A*        30.90         NaN"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1472dd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Curriculum\":\"Level 0\",\"Model\":\"DQN\",\"Mean Reward\":41.95,\"Std Reward\":1.2835497653},{\"Curriculum\":\"Level 1\",\"Model\":\"DQN\",\"Mean Reward\":45.4,\"Std Reward\":1.7435595774},{\"Curriculum\":\"Level 2\",\"Model\":\"DQN\",\"Mean Reward\":37.45,\"Std Reward\":3.2011716605},{\"Curriculum\":\"Level 3\",\"Model\":\"DQN\",\"Mean Reward\":28.3,\"Std Reward\":48.9929586778},{\"Curriculum\":\"Level 4\",\"Model\":\"DQN\",\"Mean Reward\":-198.5,\"Std Reward\":3.0740852298},{\"Curriculum\":\"Level 0\",\"Model\":\"PPO\",\"Mean Reward\":43.35,\"Std Reward\":1.1521718622},{\"Curriculum\":\"Level 1\",\"Model\":\"PPO\",\"Mean Reward\":20.55,\"Std Reward\":73.5333087791},{\"Curriculum\":\"Level 2\",\"Model\":\"PPO\",\"Mean Reward\":39.5,\"Std Reward\":2.4186773245},{\"Curriculum\":\"Level 3\",\"Model\":\"PPO\",\"Mean Reward\":41.15,\"Std Reward\":2.219797288},{\"Curriculum\":\"Level 4\",\"Model\":\"PPO\",\"Mean Reward\":30.7,\"Std Reward\":2.3259406699},{\"Curriculum\":\"Level 0\",\"Model\":\"PPO L2\",\"Mean Reward\":42.95,\"Std Reward\":1.745709025},{\"Curriculum\":\"Level 1\",\"Model\":\"PPO L2\",\"Mean Reward\":44.2,\"Std Reward\":1.9646882704},{\"Curriculum\":\"Level 2\",\"Model\":\"PPO L2\",\"Mean Reward\":39.35,\"Std Reward\":2.1041625413},{\"Curriculum\":\"Level 3\",\"Model\":\"PPO L2\",\"Mean Reward\":14.85,\"Std Reward\":71.6549195799},{\"Curriculum\":\"Level 4\",\"Model\":\"PPO L2\",\"Mean Reward\":20.55,\"Std Reward\":47.9150028697},{\"Curriculum\":\"Level 0\",\"Model\":\"A*\",\"Mean Reward\":42.25,\"Std Reward\":null},{\"Curriculum\":\"Level 1\",\"Model\":\"A*\",\"Mean Reward\":45.5,\"Std Reward\":null},{\"Curriculum\":\"Level 2\",\"Model\":\"A*\",\"Mean Reward\":40.45,\"Std Reward\":null},{\"Curriculum\":\"Level 3\",\"Model\":\"A*\",\"Mean Reward\":40.65,\"Std Reward\":null},{\"Curriculum\":\"Level 4\",\"Model\":\"A*\",\"Mean Reward\":30.9,\"Std Reward\":null}]\n"
     ]
    }
   ],
   "source": [
    "# Print dataframe as a json\n",
    "results_json = results.to_json(orient='records')\n",
    "print(results_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6716e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-cpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
